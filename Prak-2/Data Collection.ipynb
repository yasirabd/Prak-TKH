{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Data Collection</i> adalah proses pengumpulan sejumlah data yang banyak.\n",
    "Pada proses <i>Data Collection</i>, kita dapat menggunakan berbagai macam tools atau software misalanya menggunakan Web Data Collection Tool : [import.io](https://www.import.io/) \n",
    "<br><br>\n",
    "Pada praktikum kali ini, dengan menggunakan bahasa python untuk melakukan pengkoleksian data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Twitter\n",
    "Pada pengambilan data tweet di twitter memanfaatkan <i>Application Programming Interface</i> (API) dari Twitter yang bersifat <i>open source</i>.\n",
    "\n",
    "#### a. Register App\n",
    "Lakukan register app di [sini](http://apps.twitter.com). \n",
    "Pastikan mendapatkan <i>Consumer Key (API Key), Consumer Secret (API Secret), Access Token,</i> dan <i>Access Token Secret </i>.\n",
    "\n",
    "#### b. Install Tweepy (Python Library for Accessing Twitter-API)\n",
    "Untuk meng-install dapat menggunakan <u>pip install tweepy</u>.\n",
    "Dokumentasi mengenai tweepy bisa diakses di [sini](http://docs.tweepy.org/en/v3.5.0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. OAuth\n",
    "Lakukan inisialisasi untuk melakukan OAuth pada API Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    " \n",
    "consumer_key = 'CONSUMER-KEY'\n",
    "consumer_secret = 'COMSUMER-SECRET'\n",
    "access_token = 'ACCESS-TOKEN'\n",
    "access_secret = 'ACCESS-SECRET'\n",
    "     \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable <u>api</u> akan menjadi gerbang untuk akses pada API Twitter.\n",
    "\n",
    "- Berikut ini adalah salah satu contoh yang digunakan untuk menampilkan 10 items tweet pada <u>home timeline</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tweepy import Cursor\n",
    "\n",
    "i = 1\n",
    "for status in Cursor(api.home_timeline).items(10):\n",
    "    # Process a single status\n",
    "    print(i, status.text)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Menampilkan atribut dari satu tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for status in Cursor(api.home_timeline).items(1):\n",
    "    # Process a single status\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisa juga kita meletakkan file hasil <i>crawling</i> pada suatu file <i>json, csv, txt, dll</i>\n",
    "\n",
    "- JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('home_timeline.json', 'w') as f:\n",
    "    for status in Cursor(api.home_timeline).items(2):\n",
    "        # Process a single status\n",
    "        f.write(json.dumps(status._json)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvFile = open('home_timeline.csv', 'wb')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "row = [ \"user\", \"text\" ]\n",
    "csvWriter.writerow(row)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.home_timeline).items(2):\n",
    "    #Write a row to the csv file/ I use encode utf-8\n",
    "    csvWriter.writerow([tweet.user.screen_name, tweet.text.encode('utf-8')])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "with open('home_timeline.txt', 'w') as txt:\n",
    "    for status in Cursor(api.home_timeline).items(2):\n",
    "        # Process a single status\n",
    "        txt.write(status.user.screen_name + \" = \" + status.text.encode('utf-8') + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Twitter Streaming\n",
    "Pada proses ini kita mendapatkan data dengan melakukan stream langsung untuk pengambilan tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener): \n",
    "    def on_data(self, kicau):\n",
    "        print(kicau.text)\n",
    " \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_data disconnects the stream\n",
    "            return False\n",
    "        \n",
    "myStream = tweepy.Stream(auth = api.auth, listener = MyStreamListener())\n",
    "\n",
    "myStream.filter(track=['python'], async=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Wikipedia\n",
    "Wikipedia juga menyediakan API untuk mengakses/mengambil data yang kita butuhkan.\n",
    "\n",
    "#### a. Install Library Wikipedia\n",
    "Untuk meng-install menggunakan <u>pip install wikipedia</u>. Untuk dokumentasi bisa diakses di [sini](https://wikipedia.readthedocs.io/en/latest/quickstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "wikipedia.set_lang(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print wikipedia.search(\"Semarang\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print wikipedia.suggest(\"Semarng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print wikipedia.summary(\"Semarang\", sentences=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = wikipedia.page(\"Semarang\")\n",
    "\n",
    "print (page.title)\n",
    "print (page.url)\n",
    "print (page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Images & Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (page.images[0])\n",
    "print (page.links[0])\n",
    "print (page.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Geosearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print wikipedia.geosearch(-6.966667, 110.41666699999996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Foursquare (Masih Ada Kendala)\n",
    "\n",
    "#### a. Register app\n",
    "Lakukan register app di [sini](https://id.foursquare.com/developers/). Pastikan mendapatkan <i>Client ID</i> dan <i>Client Secret</i>\n",
    "\n",
    "#### b. Install Foursquare\n",
    "Install menggunakan <u>pip install foursquare</u>. Untuk link github bisa menuju ke [sini](https://github.com/mLewisLogic/foursquare) dan untuk dokumentasi bisa dibaca di [sini](https://developer.foursquare.com/docs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import foursquare\n",
    "\n",
    "client_id = \"TSILZOA3WXF2KBIF1PLMU0BGGZPUKD0RAF4NVYBDON33Z15Y\"\n",
    "client_secret = \"OLQEWJW4X0AIERO0ZBMDAPWG5ZB1LRSW4W5NFY4CJOYQF4WS\"\n",
    "\n",
    "client = foursquare.Foursquare(client_id, client_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the client object\n",
    "client = foursquare.Foursquare(client_id=client_id, client_secret=client_secret, redirect_uri='http://localhost')\n",
    "\n",
    "# Build the authorization url for your app\n",
    "auth_uri = client.oauth.auth_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Interrogate foursquare's servers to get the user's access_token\n",
    "access_token = client.oauth.get_token('XX_CODE_RETURNED_IN_REDIRECT_XX')\n",
    "\n",
    "# Apply the returned access token to the client\n",
    "client.set_access_token(access_token)\n",
    "\n",
    "# Get the user's data\n",
    "user = client.users()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Facebook\n",
    "Facebook juga menyediakan API untuk mengambil data. Namun, memiliki keterbatasan pada API-nya\n",
    "\n",
    "#### a. Register App\n",
    "Lakukan register app di [sini](https://developers.facebook.com). Untuk mendapatkan access token dari Graph API Explorer bisa menuju ke [sini](https://developers.facebook.com/tools-and-support/).\n",
    "#### b. Install facebook library\n",
    "Untuk meng-install dapat menggunakan <u>pip install facebook-sdk</u>. Dokumentasi mengenai library facebook bisa diakses di [sini](https://pypi.python.org/pypi/facebook-sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Inisialisasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import facebook\n",
    "import json\n",
    "\n",
    "token = 'TOKEN'\n",
    "\n",
    "graph = facebook.GraphAPI(token, version='2.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan post facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "post = graph.get_object(id='POST_ID')\n",
    "print(post['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan jumlah attending event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event = graph.get_object(id='EVENT_ID', fields='attending_count,declined_count')\n",
    "print(event['attending_count'])\n",
    "print(event['declined_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan jumlah teman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all of the authenticated user's friends\n",
    "friends = graph.get_connections(id='me', connection_name='friends')\n",
    "\n",
    "print(json.dumps(friends, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan comment pada post facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.put_object(parent_object='POST_ID', connection_name='comments',message='Tes API!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan update status pada wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put_wall_post\n",
    "attachment =  {\n",
    "    'name': 'Link name',\n",
    "    'link': 'https://www.example.com/',\n",
    "    'caption': 'Check out this example',\n",
    "    'description': 'This is a longer description of the attachment',\n",
    "    'picture': 'https://www.example.com/thumbnail.jpg'\n",
    "}\n",
    "\n",
    "graph.put_wall_post(message='Check this out...', attachment=attachment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan comment pada post facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put_comment\n",
    "graph.put_comment(object_id='POST_ID', message='Great post...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan 'like' pada object tertentu, misal : comment post facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put_like\n",
    "graph.put_like(object_id='COMMENT_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan post dari facebook kita dengan atribut tertentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "posts = graph.get_connections('me', 'posts', fields='message,created_time,description,caption,link,place,status_type,shares')\n",
    "while True:  # keep paginating\n",
    "    try:\n",
    "        with open('my_posts.json', 'a') as f:\n",
    "            for post in posts['data']:\n",
    "                f.write(json.dumps(post)+\"\\n\")\n",
    "            # get next page\n",
    "            posts = requests.get(posts['paging']['next']).json()\n",
    "    except KeyError:\n",
    "        # no more pages, break the loop\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan profile facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile = graph.get_object(\"me\", fields='name,location{general_info,location},languages{name,description}')\n",
    "print(json.dumps(profile, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5. Instagram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instagram juga menyediakan API untuk mengambil data. Namun, memiliki keterbatasan pada API-nya.\n",
    "\n",
    "#### a. Register App\n",
    "Lakukan register app di [sini](https://www.instagram.com/developer/). Untuk mendapatkan access token melalui link [sini](https://instagram.com/oauth/authorize/?client_id=[CLIENT_ID_HERE]&redirect_uri=http://localhost&response_type=token) dengan terlebih dahulu mendefinisikan pada app client redirect uri-nya.\n",
    "<br><br>\n",
    "Pastikan juga redirect uri yang terdapat pada app dan link di atas sama.\n",
    "\n",
    "#### b. Install instagram library\n",
    "Untuk meng-install dapat menggunakan <u>pip install python-instagram</u>. Dokumentasi mengenai library instagram bisa diakses pada github di [sini](https://github.com/facebookarchive/python-instagram). Walaupun library-nya sepertinya sudah tidak di-update lagi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inisialisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from instagram.client import InstagramAPI\n",
    "\n",
    "access_token = 'ACCESS-TOKEN'\n",
    "client_secret = 'CLIENT-SECRET'\n",
    "api = InstagramAPI(access_token=access_token, client_secret=client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recent_media, next_ = api.user_recent_media(user_id=\"USER-ID\", count=10)\n",
    "for media in recent_media:\n",
    "    print(media.caption.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hmac\n",
    "from hashlib import sha256\n",
    "\n",
    "def generate_sig(endpoint, params, secret):\n",
    "    sig = endpoint\n",
    "    for key in sorted(params.keys()):\n",
    "        sig += '|%s=%s' % (key, params[key])\n",
    "    return hmac.new(secret, sig, sha256).hexdigest()\n",
    "\n",
    "endpoint = '/media/657988443280050001_25025320'\n",
    "params = {\n",
    "    'access_token': '1397096926.dc637bd.b8b3dc8571914eb09e95772139086196',\n",
    "    'count': 10,\n",
    "}\n",
    "secret = 'ee7d8da7b1bb45dd9f2b66e75950682f'\n",
    "\n",
    "sig = generate_sig(endpoint, params, secret)\n",
    "print sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan user yang terdaftar pada app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.user(USER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan media yang disukai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.user_liked_media()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan detail user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = api.user_search('yasirabdr')\n",
    "my_usr = user[0]\n",
    "print 'User id is', my_usr.id, 'and name is ', my_usr.username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mendapatkan request masuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.user_incoming_requests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan follow user (hanya bisa pada user yang terdapat di app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.follow_user(user_id=USER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan unfollow user (hanya bisa pada user yang terdapat di app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.unfollow_user(user_id=USER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perintah lainnya yang dapat dilakukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api.block_user(user_id)\n",
    "api.unblock_user(user_id)\n",
    "api.approve_user_request(user_id)\n",
    "api.ignore_user_request(user_id)\n",
    "api.user_relationship(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Menampilkan comment pada post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.media_comments(media_id='POST-ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Menuliskan comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.create_media_comment(media_id='POST-ID', text='this is my comment!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Menghapus comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.delete_comment(media_id='POST-ID', comment_id='1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.like_media(media_id='POST-ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan unlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.unlike_media(media_id='POST-ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6. Scrapping pada web ecommerce (Bukalapak)\n",
    "Melakukan scrapping adalah melakukan ekstraksi informasi pada suatu website. Pada proses scrapping yang digunakan kali ini menggunakan library python yaitu [Scrapy](https://scrapy.org/). Scrapy adalah framework untuk melakukan ekstraksi data pada web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Install Scrapy\n",
    "Cara mudah untuk melakukan install menggunakan <u>pip install Scrapy</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Get Started with Scrapy\n",
    "Untuk memulai kita terlebih dahulu membuat sebuah projek baru dengan\n",
    "<br><br><b><pre>scrapy startproject bukalapak</pre></b><br>\n",
    "Dengan melakukan hal tersebut, maka otomatis akan menghasilkan seperti berikut:\n",
    "<br><b>\n",
    "<pre>bukalapak/\n",
    "    scrapy.cfg\n",
    "   bukalapak/\n",
    "       __init__.py\n",
    "       items.py\n",
    "       pipelines.py\n",
    "       settings.py\n",
    "       spiders/\n",
    "           __init__.py\n",
    "</pre>\n",
    "</b><br>\n",
    "Scrapy adalah <b>Object Oriented</b> programming dalam mendefinisikan item dan spider. Berikut penjelasan dari tiap item\n",
    "- <b>scrapy.cfg</b><br> \n",
    "It is a project configuration file which contains information for setting module for the project along with its deployment information.<br><br>\n",
    "- <b>bukalapak</b> : application directory\n",
    "<br><br>\n",
    "- <b>items.py</b><br>\n",
    "Items are containers that will be loaded with the scraped data; they work like simple <b>Python dicts</b>. While one can use plain Python dicts with Scrapy, Items provide additional protection against populating undeclared fields, preventing typos. They are declared by creating a <b>scrapy.Item</b> class and defining its attributes as <b>scrapy.Field</b> objects.\n",
    "<br><br>\n",
    "- <b>pipelines.py</b><br>\n",
    "After an item has been scraped by a spider, it is sent to the Item <b>Pipeline</b> which processes it through several components that are executed sequentially.Each item pipeline component is a Python class which has to implement a method called <b>process_item</b> to process scraped items. It receives an item and performs an action on it, also decides if the item should continue through the pipeline or should be dropped and and not processed any longer. If it wants to drop an item then it raises <b>DropItem</b> exception to drop it.\n",
    "<br><br>\n",
    "- <b>settings.py</b> : <br>\n",
    "It allows one to customise the behaviour of all Scrapy <b>components</b>, including the core, extensions, pipelines and spiders themselves. It provides a global namespace of key-value mappings that the code can use to pull configuration values from.\n",
    "<br><br>\n",
    "- <b>spiders</b> : <br>\n",
    "Spiders is a directory which contains all <b>spiders/crawlers</b> as Python classes. Whenever one runs/crawls any spider then scrapy looks into this directory and tries to find the spider with its name provided by user. Spiders define how a certain site or a group of sites will be scraped, including how to perform the crawl and how to extract data from their pages. In other words, Spiders are the place where one defines the custom behavior for crawling and parsing pages for a particular site.Spiders have to define three major attributes i.e <b>start_urls</b> which tells which URLs are to be scrapped, <b>allowed_domains</b> which defines  only those domain names which need to scraped and <b>parse</b> is a method which is called when any response comes from lodged requests. These attributes are important because these constitute the base of Spider definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Lets Scrap\n",
    "Dalam melakukan scrapping terdapat 3 hal yang perlu dilakukan yaitu:\n",
    "1. Melakukan update <b>items.py</b> dengan mengisi field yang akan di extract.\n",
    "2. Membuat sebuah <b>Spider</b> baru untuk mendefinisikan <b>allowed_domains, start_urls, parse</b> method\n",
    "3. Melakukan update <b>pipelines.py</b> untuk data processing lebih jauh.\n",
    "\n",
    "Sekarang ayo kita melakukan scrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update <b>items.py</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define here the models for your scraped items\n",
    "#\n",
    "# See documentation in:\n",
    "# http://doc.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class BukalapakItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    product_name = scrapy.Field()\n",
    "    product_category = scrapy.Field()\n",
    "    product_currency_price = scrapy.Field()\n",
    "    product_price = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create new <b>Spider</b>\n",
    "Untuk membuatnya, kita bisa menggunakan default utility <b>genspider</b>\n",
    "<br><br><b><pre>\n",
    "scrapy genspider BukalapakProductSpider bukalapak.com\n",
    "</pre></b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update <b>BukalapakProductSpider.py</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from bukalapak.items import BukalapakItem\n",
    "\n",
    "class BukalapakProductSpider(scrapy.Spider):\n",
    "    name = \"BukalapakDeals\"\n",
    "    allowed_domains = [\"bukalapak.com\"]\n",
    "\n",
    "    #Use working product URL below\n",
    "    start_urls = [\n",
    "        \"https://www.bukalapak.com/p/komputer/laptop/43mglk-jual-laptop-hp-8560w-elitebook-workstation-core-i7\", \n",
    "        \"https://www.bukalapak.com/p/komputer/laptop/3sz46v-jual-hp-1000\",\n",
    "        \"https://www.bukalapak.com/p/komputer/laptop/43ohlq-jual-dell-e6420-core-i5\", \n",
    "        \"https://www.bukalapak.com/p/komputer/laptop/45uqjz-jual-macbook-white-core-2-duo-mulus-normal-lancar\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        items = BukalapakItem()\n",
    "        name = response.xpath('//h1[@itemprop=\"name\"]/text()').extract()\n",
    "        category = response.xpath('//dd[@itemprop=\"category\"]/text()').extract()\n",
    "        currency_price = response.xpath('//span[@itemprop=\"priceCurrency\"]/text()').extract()\n",
    "        price = response.xpath('//span[@itemprop=\"price\"]/text()').extract()\n",
    "\n",
    "        items['product_name'] = ''.join(name).strip()\n",
    "        items['product_category'] = ''.join(category).strip()\n",
    "        items['product_currency_price'] = ''.join(currency_price).strip()\n",
    "        items['product_price'] = ''.join(price).strip()\n",
    "        \n",
    "        yield items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pipeline<br>\n",
    "Pipeline classes implement <b>process_item</b> method which is called each and every time whenever items is being yielded by a Spider. It takes <b>item</b> and <b>spider</b> class as arguments and returns a <b>dict</b> object. So for this example, we are just returning item dict as it is.\n",
    "<br><br>\n",
    "Untuk menggunakan <b>pipeline</b> terlebih dahulu melakukan enable pada <b>settings.py</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure item pipelines\n",
    "# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html\n",
    "ITEM_PIPELINES = {\n",
    "    'amazon.pipelines.AmazonPipeline': 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Melakukan <b>crawling</b>\n",
    "Untuk melakukan crawing dan menyimpannya pada sebuah file json, gunakan perintah berikut\n",
    "<br><br><b>scrapy crawl BukalapakDeals -o items.json</b><br><br>\n",
    "Berikut output yang dihasilkan pada <b>items.json</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[\n",
    "{\"product_category\": \"Laptop\", \"product_price\": \"6.000.000\", \"product_name\": \"Laptop HP 8560W EliteBook Workstation Core i7\", \"product_currency_price\": \"Rp\"},\n",
    "{\"product_category\": \"Laptop\", \"product_price\": \"2.400.000\", \"product_name\": \"HP 1000\", \"product_currency_price\": \"Rp\"},\n",
    "{\"product_category\": \"Laptop\", \"product_price\": \"3.200.000\", \"product_name\": \"DELL E6420 CORE I5\", \"product_currency_price\": \"Rp\"},\n",
    "{\"product_category\": \"Laptop\", \"product_price\": \"2.950.000\", \"product_name\": \"Macbook White Core 2 Duo Mulus , Normal,  Lancar\", \"product_currency_price\": \"Rp\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
